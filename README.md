# Snowflake_Airflow_Practice
Основная цель этого задания — получить знания о Snowflake как столбцовой базе данных и ее основных функциях.
## Описание задания
Требуется создать небольшое хранилище данных,данные в которое будут загружаться и обрабатываться (ETL-процесс)средствами Airflow.

![image](https://github.com/user-attachments/assets/0af996c0-d002-475a-9ee2-aea44303f953)

Для обох видов загрузки данных будут созданы два отдельных DAG

## Порядок выполнения задания 
1) Создание аккаунта на Snowflake
2) Создание процедуры и запуск ее с Airflow для загрузки "сырых" данных в Internal Snowflake Stage.
3) Создание пайплайна ,которые будет мониториться снова через Airflow.
4) Создание процесса регистрации, который будет регистрировать количество затронутых строк (вставка, обновление) в отдельную таблицу аудита.
5) Создание 2 запросов DDL и 2 запросов DML, используя time-travel функцию в Snowflake.
6) Создание безопасного представление для любой таблицы фактов и политика безопасности на уровне строк.\

## Мои шаги по решению
1) Главная задача,как по мне,грамотно настроить подключение в Airflow для Snowflake.
2) Создание таблиц одним запросом в Snowflake в Worksheets
3) Написание DAGа в VS Code
